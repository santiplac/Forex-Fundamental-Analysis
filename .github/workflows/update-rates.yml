name: Update Interest Rates (100% Web Scraping - No APIs)
on:
  schedule:
    - cron: '0 8 * * *'  # Daily at 8:00 AM UTC
  workflow_dispatch:

jobs:
  update-rates:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 lxml --break-system-packages
      
      - name: Create rates directory
        run: mkdir -p rates
      
      - name: Fetch all rates via web scraping
        run: |
          cat > fetch_rates.py << 'EOFPYTHON'
          import requests
          from bs4 import BeautifulSoup
          import json
          import re
          from datetime import date
          import time
          
          HEADERS = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
              'Accept-Language': 'en-US,en;q=0.9',
          }
          
          def clean_rate(text):
              """Extract and validate numeric rate"""
              if not text:
                  return None
              text = str(text).strip().replace('%', '').replace(',', '.')
              match = re.search(r'(-?\d+\.?\d*)', text)
              if match:
                  try:
                      val = float(match.group(1))
                      if -5 <= val <= 25:
                          return match.group(1)
                  except:
                      pass
              return None
          
          def fetch_trading_economics():
              """Primary source: Trading Economics"""
              print("\n" + "="*70)
              print("SOURCE 1: Trading Economics")
              print("="*70)
              
              try:
                  url = "https://tradingeconomics.com/country-list/interest-rate?continent=world"
                  r = requests.get(url, headers=HEADERS, timeout=15)
                  soup = BeautifulSoup(r.content, 'lxml')
                  
                  rates = {}
                  country_map = {
                      'United States': 'USD',
                      'Euro Area': 'EUR', 
                      'United Kingdom': 'GBP',
                      'Japan': 'JPY',
                      'Canada': 'CAD',
                      'Australia': 'AUD',
                      'Switzerland': 'CHF',
                      'New Zealand': 'NZD'
                  }
                  
                  table = soup.find('table', {'class': 'table'})
                  if table:
                      for row in table.find_all('tr')[1:]:
                          cols = row.find_all('td')
                          if len(cols) >= 2:
                              country = cols[0].get_text(strip=True)
                              rate_text = cols[1].get_text(strip=True)
                              
                              for country_name, currency in country_map.items():
                                  if country_name.lower() in country.lower():
                                      rate = clean_rate(rate_text)
                                      if rate is not None:
                                          rates[currency] = rate
                                          print(f"  ‚úì {currency}: {rate}%")
                                          break
                  
                  missing = [c for c in country_map.values() if c not in rates]
                  if missing:
                      print(f"  ‚ö†Ô∏è  Missing: {', '.join(missing)}")
                  
                  return rates
                  
              except Exception as e:
                  print(f"  ‚ùå Error: {e}")
                  return {}
          
          def fetch_global_rates(currency):
              """Backup source: Global-Rates.com (individual pages)"""
              
              urls = {
                  'USD': 'central-bank-america/fed-interest-rate.aspx',
                  'EUR': 'central-bank-europe/ecb-interest-rate.aspx',
                  'GBP': 'central-bank-england/boe-interest-rate.aspx',
                  'JPY': 'central-bank-japan/boj-interest-rate.aspx',
                  'CHF': 'central-bank-switzerland/snb-interest-rate.aspx',
                  'CAD': 'central-bank-canada/boc-interest-rate.aspx',
                  'AUD': 'central-bank-australia/rba-interest-rate.aspx',
                  'NZD': 'central-bank-new-zealand/rbnz-interest-rate.aspx'
              }
              
              if currency not in urls:
                  return None
              
              try:
                  url = f"https://www.global-rates.com/en/interest-rates/central-banks/{urls[currency]}"
                  r = requests.get(url, headers=HEADERS, timeout=10)
                  soup = BeautifulSoup(r.content, 'lxml')
                  
                  # Method 1: Look for table with "Current" in it
                  for table in soup.find_all('table'):
                      for row in table.find_all('tr'):
                          cells = row.find_all(['td', 'th'])
                          if len(cells) >= 2:
                              header = cells[0].get_text(strip=True).lower()
                              if 'current' in header and 'rate' in header:
                                  rate = clean_rate(cells[1].get_text(strip=True))
                                  if rate:
                                      return rate
                  
                  # Method 2: Find first table, get second row, second column
                  table = soup.find('table')
                  if table:
                      rows = table.find_all('tr')
                      if len(rows) >= 2:
                          cols = rows[1].find_all('td')
                          if len(cols) >= 2:
                              rate = clean_rate(cols[1].get_text(strip=True))
                              if rate:
                                  return rate
                  
                  # Method 3: Search entire page for rate pattern
                  text = soup.get_text()
                  patterns = [
                      r'Current.*?rate.*?(\d+\.?\d*)%',
                      r'interest rate.*?(\d+\.?\d*)%',
                      r'(\d+\.?\d*)%.*?current'
                  ]
                  
                  for pattern in patterns:
                      match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
                      if match:
                          rate = clean_rate(match.group(1))
                          if rate:
                              return rate
                  
              except Exception as e:
                  print(f"    Error fetching {currency}: {e}")
              
              return None
          
          def fetch_investopedia_calendar():
              """Alternative source: Investopedia Economic Calendar"""
              print("\n" + "="*70)
              print("SOURCE 3: Investopedia Economic Calendar")
              print("="*70)
              
              try:
                  url = "https://www.investopedia.com/economic-calendar/"
                  r = requests.get(url, headers=HEADERS, timeout=15)
                  soup = BeautifulSoup(r.content, 'lxml')
                  
                  rates = {}
                  text = soup.get_text()
                  
                  # Look for interest rate mentions
                  currency_patterns = {
                      'USD': [r'(?:US|Fed|Federal).*?(?:rate|FFR).*?(\d+\.?\d*)%', r'(\d+\.?\d*)%.*?(?:Fed|Federal)'],
                      'EUR': [r'(?:ECB|Euro).*?(?:rate).*?(\d+\.?\d*)%', r'(\d+\.?\d*)%.*?ECB'],
                      'GBP': [r'(?:BoE|Bank.*?England).*?(\d+\.?\d*)%', r'(\d+\.?\d*)%.*?BoE'],
                      'JPY': [r'(?:BoJ|Japan).*?(\d+\.?\d*)%', r'(\d+\.?\d*)%.*?BoJ'],
                      'CAD': [r'(?:BoC|Canada).*?(\d+\.?\d*)%', r'(\d+\.?\d*)%.*?Canada'],
                      'AUD': [r'(?:RBA|Australia).*?(\d+\.?\d*)%', r'(\d+\.?\d*)%.*?RBA'],
                      'CHF': [r'(?:SNB|Swiss).*?(\d+\.?\d*)%', r'(\d+\.?\d*)%.*?SNB'],
                      'NZD': [r'(?:RBNZ|New Zealand).*?(\d+\.?\d*)%', r'(\d+\.?\d*)%.*?(?:New Zealand|RBNZ)']
                  }
                  
                  for currency, patterns in currency_patterns.items():
                      for pattern in patterns:
                          match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
                          if match:
                              rate = clean_rate(match.group(1))
                              if rate:
                                  rates[currency] = rate
                                  print(f"  ‚úì {currency}: {rate}%")
                                  break
                      if currency in rates:
                          break
                  
                  return rates
                  
              except Exception as e:
                  print(f"  ‚ùå Error: {e}")
                  return {}
          
          def fetch_myfxbook():
              """Alternative: MyFxBook"""
              print("\n" + "="*70)
              print("SOURCE 4: MyFxBook")
              print("="*70)
              
              try:
                  url = "https://www.myfxbook.com/forex-economic-calendar/interest-rates"
                  r = requests.get(url, headers=HEADERS, timeout=15)
                  text = r.text
                  
                  rates = {}
                  
                  # Look for currency patterns in the page
                  patterns = {
                      'USD': r'(?:USD|US Dollar|United States).*?(\d+\.?\d*)%',
                      'EUR': r'(?:EUR|Euro).*?(\d+\.?\d*)%',
                      'GBP': r'(?:GBP|Pound|UK).*?(\d+\.?\d*)%',
                      'JPY': r'(?:JPY|Yen|Japan).*?(\d+\.?\d*)%',
                      'CAD': r'(?:CAD|Canadian|Canada).*?(\d+\.?\d*)%',
                      'AUD': r'(?:AUD|Australian|Australia).*?(\d+\.?\d*)%',
                      'CHF': r'(?:CHF|Swiss|Switzerland).*?(\d+\.?\d*)%',
                      'NZD': r'(?:NZD|New Zealand|Kiwi).*?(\d+\.?\d*)%'
                  }
                  
                  for currency, pattern in patterns.items():
                      match = re.search(pattern, text, re.IGNORECASE)
                      if match:
                          rate = clean_rate(match.group(1))
                          if rate:
                              rates[currency] = rate
                              print(f"  ‚úì {currency}: {rate}%")
                  
                  return rates
                  
              except Exception as e:
                  print(f"  ‚ùå Error: {e}")
                  return {}
          
          # ============================================
          # MAIN EXECUTION
          # ============================================
          
          print("\n" + "="*70)
          print("FETCHING INTEREST RATES - 100% WEB SCRAPING")
          print("="*70)
          
          final_rates = {}
          
          # Source 1: Trading Economics (primary)
          te_rates = fetch_trading_economics()
          for curr, rate in te_rates.items():
              if curr not in final_rates:
                  final_rates[curr] = {'value': rate, 'source': 'TradingEconomics'}
          
          time.sleep(1)
          
          # Source 2: Global-Rates.com (for missing currencies)
          missing = ['USD', 'EUR', 'GBP', 'JPY', 'CAD', 'AUD', 'CHF', 'NZD']
          missing = [c for c in missing if c not in final_rates]
          
          if missing:
              print("\n" + "="*70)
              print(f"SOURCE 2: Global-Rates.com (for {', '.join(missing)})")
              print("="*70)
              
              for currency in missing:
                  rate = fetch_global_rates(currency)
                  if rate:
                      final_rates[currency] = {'value': rate, 'source': 'GlobalRates'}
                      print(f"  ‚úì {currency}: {rate}%")
                  time.sleep(0.5)
          
          # Source 3: Investopedia (for still missing)
          missing = [c for c in ['USD', 'EUR', 'GBP', 'JPY', 'CAD', 'AUD', 'CHF', 'NZD'] if c not in final_rates]
          if missing:
              inv_rates = fetch_investopedia_calendar()
              for curr, rate in inv_rates.items():
                  if curr not in final_rates:
                      final_rates[curr] = {'value': rate, 'source': 'Investopedia'}
              time.sleep(1)
          
          # Source 4: MyFxBook (for still missing)
          missing = [c for c in ['USD', 'EUR', 'GBP', 'JPY', 'CAD', 'AUD', 'CHF', 'NZD'] if c not in final_rates]
          if missing:
              myfx_rates = fetch_myfxbook()
              for curr, rate in myfx_rates.items():
                  if curr not in final_rates:
                      final_rates[curr] = {'value': rate, 'source': 'MyFxBook'}
          
          # Save results
          print("\n" + "="*70)
          print("SAVING RESULTS")
          print("="*70)
          
          today = str(date.today())
          
          for currency, data in final_rates.items():
              rate_data = {
                  'observations': [{
                      'value': data['value'],
                      'date': today,
                      'source': data['source']
                  }]
              }
              
              with open(f'rates/{currency}.json', 'w') as f:
                  json.dump(rate_data, f, indent=2)
              
              print(f"  üíæ {currency}: {data['value']}% ({data['source']})")
          
          # Validation
          print("\n" + "="*70)
          print("VALIDATION")
          print("="*70)
          
          required = ['USD', 'EUR', 'GBP', 'JPY', 'CAD', 'AUD', 'CHF', 'NZD']
          missing = [c for c in required if c not in final_rates]
          
          if missing:
              print(f"\n‚ùå MISSING CURRENCIES: {', '.join(missing)}")
              print("\nWorkflow FAILED - incomplete data")
              exit(1)
          else:
              print("\n‚úÖ ALL 8 CURRENCIES FETCHED!")
              print("\nFinal rates:")
              for curr in required:
                  data = final_rates[curr]
                  print(f"  {curr}: {data['value']}% ({data['source']})")
          
          EOFPYTHON
          
          python fetch_rates.py
      
      - name: Display results
        run: |
          echo ""
          echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
          echo "‚ïë      FINAL RATES (100% WEB SCRAPING)           ‚ïë"
          echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
          echo ""
          
          for currency in USD EUR GBP JPY AUD CAD CHF NZD; do
            if [ -f "rates/$currency.json" ]; then
              echo "[$currency]"
              python3 -c "
          import json
          with open('rates/$currency.json') as f:
              data = json.load(f)
              obs = data['observations'][0]
              print(f\"  Rate: {obs['value']}%\")
              print(f\"  Date: {obs['date']}\")
              print(f\"  Source: {obs['source']}\")
          "
              echo ""
            fi
          done
      
      - name: Commit and push
        run: |
          git config user.name github-actions
          git config user.email github-actions@github.com
          git add rates/
          git pull --rebase
          git diff --quiet && git diff --staged --quiet || (git commit -m "üîÑ Auto-update rates $(date +'%Y-%m-%d %H:%M UTC') - 100% web scraping" && git push)
